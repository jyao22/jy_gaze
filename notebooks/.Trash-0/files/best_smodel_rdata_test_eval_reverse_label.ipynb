{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662efc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import wandb\n",
    "\n",
    "import datasets\n",
    "# from utils import select_device, natural_keys, gazeto3d, angular, getArch\n",
    "from utils import select_device, natural_keys, gazeto3d, angular, getArch\n",
    "from model import L2CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd3bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 "
     ]
    }
   ],
   "source": [
    "# check if we have the correct number of checkpoint files \n",
    "ppath ='/project/results/output/snapshots/' \n",
    "for fold in range(15):\n",
    "    foldstr = f\"fold{fold:0>2}\"\n",
    "    cpath =os.path.join(ppath, foldstr)\n",
    "    files = os.listdir(cpath)\n",
    "    print(len(files), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b3b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"Parse input arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Gaze estimation using L2CSNet .')\n",
    "     # Gaze360\n",
    "    parser.add_argument(\n",
    "        '--gaze360image_dir', dest='gaze360image_dir', help='Directory path for gaze images.',\n",
    "        default='datasets/Gaze360/Image', type=str)\n",
    "    parser.add_argument(\n",
    "        '--gaze360label_dir', dest='gaze360label_dir', help='Directory path for gaze labels.',\n",
    "        default='datasets/Gaze360/Label/test.label', type=str)\n",
    "    # mpiigaze\n",
    "    parser.add_argument(\n",
    "        '--gazeMpiimage_dir', dest='gazeMpiimage_dir', help='Directory path for gaze images.',\n",
    "        default='datasets/MPIIFaceGaze/Image', type=str)\n",
    "    parser.add_argument(\n",
    "        '--gazeMpiilabel_dir', dest='gazeMpiilabel_dir', help='Directory path for gaze labels.',\n",
    "        default='datasets/MPIIFaceGaze/Label', type=str)\n",
    "    # Important args -------------------------------------------------------------------------------------------------------\n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "    parser.add_argument(\n",
    "        '--dataset', dest='dataset', help='gaze360, mpiigaze',\n",
    "        default= \"gaze360\", type=str)\n",
    "    parser.add_argument(\n",
    "        '--snapshot', dest='snapshot', help='Path to the folder contains models.', \n",
    "        default='output/snapshots/L2CS-gaze360-_loader-180-4-lr', type=str)\n",
    "    parser.add_argument(\n",
    "        '--evalpath', dest='evalpath', help='path for the output evaluating gaze test.',\n",
    "        default=\"evaluation/L2CS-gaze360-_loader-180-4-lr\", type=str)\n",
    "    parser.add_argument(\n",
    "        '--gpu',dest='gpu_id', help='GPU device id to use [0]',\n",
    "        default=\"0\", type=str)\n",
    "    parser.add_argument(\n",
    "        '--batch_size', dest='batch_size', help='Batch size.',\n",
    "        default=100, type=int)\n",
    "    parser.add_argument(\n",
    "        '--arch', dest='arch', help='Network architecture, can be: ResNet18, ResNet34, [ResNet50], ''ResNet101, ResNet152, Squeezenet_1_0, Squeezenet_1_1, MobileNetV2',\n",
    "        default='ResNet50', type=str)\n",
    "    # ---------------------------------------------------------------------------------------------------------------------\n",
    "    # Important args ------------------------------------------------------------------------------------------------------\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed29c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nothing:\n",
    "    pass\n",
    "args = Nothing()\n",
    "args.gazeMpiimage_dir = '/project/data/Image'  # syn data \n",
    "args.gazeMpiilabel_dir = '/project/data/Label'  # syn label\n",
    "args.output = '/project/results/soutput/snapshots/'  # real model\n",
    "args.dataset = 'mpiigaze'\n",
    "args.snapshot='/project/results/soutput/snapshots/'  # real data model\n",
    "args.evalpath = '/project/results/rsoutput/evaluation/'\n",
    "args.gpu_id = '0,1,2,3'\n",
    "args.gpu_id = '0'\n",
    "args.batch_size = 20\n",
    "args.arch = 'ResNet50'\n",
    "args.bins=28\n",
    "args.angle = 180\n",
    "args.bin_width = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e11321",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=args.batch_size\n",
    "arch=args.arch\n",
    "data_set=args.dataset\n",
    "evalpath =args.evalpath\n",
    "snapshot_path = args.snapshot\n",
    "bins=args.bins\n",
    "angle=args.angle\n",
    "bin_width=args.bin_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee43ec23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README\tdaoutput  output  rsoutput  soutput  sroutput\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0504fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parse_args()\n",
    "cudnn.enabled = True\n",
    "gpu = select_device(args.gpu_id, batch_size=args.batch_size)\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "model_used=getArch(arch, bins)  #resnet50 and 28 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "238ef93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold=2\n",
    "# folder = os.listdir(os.path.join(snapshot_path, \"fold\" + f'{fold:0>2}'))\n",
    "# folder.sort(key=natural_keys)\n",
    "# folder.pop(-1)  #remove the tensorboard file\n",
    "# # print(folder)\n",
    "# epochs = folder[3]\n",
    "# os.path.join(snapshot_path+\"fold\"+f'{fold:0>2}', epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12438eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(evalpath, snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9f4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7434f02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=0 --06/17/2022 15:17:48---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=1\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=1 --06/17/2022 15:18:06---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=2\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=2 --06/17/2022 15:18:19---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=3\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=3 --06/17/2022 15:18:33---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=4\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=4 --06/17/2022 15:18:46---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=5\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=5 --06/17/2022 15:18:59---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=6\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=6 --06/17/2022 15:19:12---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=7\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=7 --06/17/2022 15:19:25---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=8\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=8 --06/17/2022 15:19:38---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=9\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=9 --06/17/2022 15:19:51---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=10\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=10 --06/17/2022 15:20:05---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=11\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=11 --06/17/2022 15:20:18---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=12\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=12 --06/17/2022 15:20:31---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=13\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=13 --06/17/2022 15:20:44---------\n",
      "epochs=epoch_39.pkl\n",
      "fold=14\n",
      "/project/data/Label\n",
      "0 items removed from dataset that have an angle > 180\n",
      "\n",
      "test configuration equal gpu_id=cuda:0, batch_size=20, model_arch=ResNet50\n",
      "Start testing dataset=mpiigaze, FOLD=14 --06/17/2022 15:20:57---------\n",
      "epochs=epoch_39.pkl\n",
      "CPU times: user 2min 58s, sys: 1min 8s, total: 4min 6s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ims_errs = {}\n",
    "\n",
    "for fold in range(15):\n",
    "    print(f\"fold={fold}\")\n",
    "    \n",
    "    now = datetime.utcnow()\n",
    "    now = now.astimezone(timezone('US/Pacific'))\n",
    "    date_format='%m/%d/%Y %H:%M:%S'\n",
    "    now = now.strftime(date_format)\n",
    "    \n",
    "    print(args.gazeMpiilabel_dir)\n",
    "    folder = os.listdir(args.gazeMpiilabel_dir)\n",
    "    folder.sort()  #individual label files\n",
    "    testlabelpathcombined = [os.path.join(args.gazeMpiilabel_dir, j) for j in folder] \n",
    "#     print(testlabelpathcombined)\n",
    "#     print(args.gazeMpiimage_dir)\n",
    "    gaze_dataset=datasets.Mpiigaze(testlabelpathcombined, args.gazeMpiimage_dir, transformations, False, angle, fold)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=gaze_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True)\n",
    "\n",
    "    fold_path = os.path.join(evalpath, 'fold' + f'{fold:0>2}'+'/')  #for evaluation\n",
    "#     print(f\"fold_path is {fold_path}\")\n",
    "#     if not os.path.exists(fold_path):\n",
    "#         os.makedirs(fold_path)\n",
    "\n",
    "#     if not os.path.exists(os.path.join(evalpath, f\"fold\"+str(fold))):\n",
    "#         os.makedirs(os.path.join(evalpath, f\"fold\"+str(fold)))\n",
    "\n",
    "    # list all epochs for testing\n",
    "    folder = os.listdir(os.path.join(snapshot_path, \"fold\" + f'{fold:0>2}'))\n",
    "    folder.sort(key=natural_keys)\n",
    "    folder.pop(-1)  #remove the tensorboard file, now all snapshot files\n",
    "#     print(f\"folder={folder}\")  #contains all the checkpoint files\n",
    "                    \n",
    "\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "#     with open(os.path.join(evalpath, os.path.join(\"fold\"+f'{fold:0>2}', data_set+\".log\")), 'w') as outfile:\n",
    "        \n",
    "    configuration = (f\"\\ntest configuration equal gpu_id={gpu}, batch_size={batch_size}, model_arch={arch}\\n\"\n",
    "                     f\"Start testing dataset={data_set}, FOLD={fold} --{now}---------\")\n",
    "    print(configuration)\n",
    "\n",
    "#     outfile.write(configuration)\n",
    "    epoch_list=[]\n",
    "    avg_MAE=[]\n",
    "    for epochs in folder: \n",
    "        x = ''.join(filter(lambda i: i.isdigit(), epochs))\n",
    "        x = int(x)\n",
    "        if x != 39:\n",
    "            continue\n",
    "#         print(f\"epochs={epochs}\")\n",
    "        model=model_used\n",
    "        checkpoint = torch.load(os.path.join(snapshot_path+\"fold\"+f'{fold:0>2}', epochs))\n",
    "#         print(f\"checkpoint={checkpoint}\")\n",
    "        saved_state_dict = checkpoint['model_state_dict']\n",
    "        model= nn.DataParallel(model,device_ids=[0])\n",
    "        model.load_state_dict(saved_state_dict)\n",
    "        model.cuda(gpu)\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        idx_tensor = [idx for idx in range(28)]\n",
    "        idx_tensor = torch.FloatTensor(idx_tensor).cuda(gpu)\n",
    "        avg_error = .0\n",
    "        \n",
    "        print(f\"epochs={epochs}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for j, (images, labels, cont_labels, name) in enumerate(test_loader):\n",
    "#                 print(f\"name={name}\")\n",
    "                images = Variable(images).cuda(gpu)\n",
    "                total += cont_labels.size(0)\n",
    "\n",
    "                label_pitch = cont_labels[:,0].float()*np.pi/180\n",
    "                label_yaw = cont_labels[:,1].float()*np.pi/180\n",
    "\n",
    "                gaze_pitch, gaze_yaw = model(images)\n",
    "\n",
    "                # Binned predictions\n",
    "                _, pitch_bpred = torch.max(gaze_pitch.data, 1)\n",
    "                _, yaw_bpred = torch.max(gaze_yaw.data, 1)\n",
    "\n",
    "                # Continuous predictions\n",
    "                pitch_predicted = softmax(gaze_pitch)\n",
    "                yaw_predicted = softmax(gaze_yaw)\n",
    "\n",
    "                # mapping from binned (0 to 28) to angels (-42 to 42)                \n",
    "                pitch_predicted = \\\n",
    "                    torch.sum(pitch_predicted * idx_tensor, 1).cpu() * 3 - 42\n",
    "                yaw_predicted = \\\n",
    "                    torch.sum(yaw_predicted * idx_tensor, 1).cpu() * 3 - 42\n",
    "\n",
    "                pitch_predicted = pitch_predicted*np.pi/180\n",
    "                yaw_predicted = yaw_predicted*np.pi/180\n",
    "\n",
    "#                 print(f\"name={name}\")\n",
    "                errors = []\n",
    "                for idx, (p,y,pl,yl) in enumerate(zip(pitch_predicted, yaw_predicted, label_yaw, label_pitch)):\n",
    "                    angular_error = angular(gazeto3d([p,y]), gazeto3d([pl,yl]))\n",
    "#                         print(f\"type OF angular error {type(angular_error)}\")\n",
    "#                     print(f\"angular error={angular_error}\")\n",
    "                    avg_error += angular_error\n",
    "                    angular_error = angular_error.item()  #numpy float to float\n",
    "                    errors.append(angular_error)\n",
    "                tdict = dict(zip(name, errors))\n",
    "                ims_errs.update(tdict)\n",
    "        epoch_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065622ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_errors = dict(sorted(ims_errs.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "211ce764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20*15/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fcabdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> p10/face/1064.jpg\n",
      "<class 'float'> 49.95993790441597\n",
      "<class 'str'> p02/face/1384.jpg\n",
      "<class 'float'> 48.157252171484\n",
      "<class 'str'> p10/face/2584.jpg\n",
      "<class 'float'> 46.8934420773529\n",
      "<class 'str'> p05/face/1764.jpg\n",
      "<class 'float'> 43.044729570140994\n"
     ]
    }
   ],
   "source": [
    "ix=0\n",
    "for k in images_errors:\n",
    "    if ix >3:\n",
    "        break\n",
    "    print(type(k), k)\n",
    "    print(type(images_errors[k]), images_errors[k])\n",
    "    ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee3c04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.array(list(images_errors.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7f4885c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'degree')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(errors, bins=40)\n",
    "plt.title(\"error distribution: syn model real data\")\n",
    "plt.xlabel(\"degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d6d7709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.660605594369075\n"
     ]
    }
   ],
   "source": [
    "mean_error = errors.mean()\n",
    "print(mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0872f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p10/face/1064.jpg 49.95993790441597\n",
      "p02/face/1384.jpg 48.157252171484\n",
      "p10/face/2584.jpg 46.8934420773529\n",
      "p05/face/1764.jpg 43.044729570140994\n",
      "p14/face/1051.jpg 42.77265594608241\n",
      "p14/face/761.jpg 42.2928476603808\n",
      "p14/face/1021.jpg 41.861920605730106\n",
      "p06/face/947.jpg 41.690438330259376\n",
      "p08/face/1617.jpg 41.44541005912725\n",
      "p14/face/252.jpg 41.25945392403653\n",
      "p06/face/957.jpg 41.22029961962576\n",
      "p10/face/1478.jpg 41.18101972395625\n",
      "p12/face/493.jpg 41.11558834940966\n",
      "p06/face/380.jpg 41.1041057673431\n",
      "p06/face/665.jpg 41.01282182906449\n",
      "p12/face/534.jpg 40.84604253446143\n",
      "p14/face/398.jpg 40.5060068345106\n",
      "p14/face/1467.jpg 40.48195193873705\n",
      "p14/face/1215.jpg 40.19778594386257\n",
      "p06/face/112.jpg 40.196617718739645\n",
      "p14/face/1023.jpg 39.84434359451673\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "for k, v in images_errors.items():\n",
    "    if ix >20:\n",
    "        break\n",
    "    print(k, v)\n",
    "    ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5fd60e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd22731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p10/face/1064.jpg 49.95993790441597\n",
      "p02/face/1384.jpg 48.157252171484\n",
      "p10/face/2584.jpg 46.8934420773529\n",
      "p05/face/1764.jpg 43.044729570140994\n",
      "p14/face/1051.jpg 42.77265594608241\n",
      "p14/face/761.jpg 42.2928476603808\n",
      "p14/face/1021.jpg 41.861920605730106\n",
      "p06/face/947.jpg 41.690438330259376\n",
      "p08/face/1617.jpg 41.44541005912725\n",
      "p14/face/252.jpg 41.25945392403653\n",
      "p06/face/957.jpg 41.22029961962576\n",
      "p10/face/1478.jpg 41.18101972395625\n",
      "p12/face/493.jpg 41.11558834940966\n",
      "p06/face/380.jpg 41.1041057673431\n",
      "p06/face/665.jpg 41.01282182906449\n",
      "p12/face/534.jpg 40.84604253446143\n",
      "p14/face/398.jpg 40.5060068345106\n",
      "p14/face/1467.jpg 40.48195193873705\n",
      "p14/face/1215.jpg 40.19778594386257\n",
      "p06/face/112.jpg 40.196617718739645\n",
      "p14/face/1023.jpg 39.84434359451673\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "for k, v in images_errors.items():\n",
    "    if ix >20:\n",
    "        break\n",
    "    print(k, v)\n",
    "    ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d561f4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p14/face/238.jpg 0.3884347907803918\n",
      "p11/face/95.jpg 0.35737316322277235\n",
      "p08/face/2036.jpg 0.3456420306336041\n",
      "p09/face/2222.jpg 0.3386396241643315\n",
      "p06/face/749.jpg 0.308652482039855\n",
      "p09/face/1322.jpg 0.30831588493241535\n",
      "p00/face/1687.jpg 0.30791675745106795\n",
      "p13/face/763.jpg 0.2937963934672409\n",
      "p04/face/105.jpg 0.2919145751738629\n",
      "p11/face/2546.jpg 0.2879034805986369\n",
      "p00/face/1498.jpg 0.2878471173599586\n",
      "p11/face/2720.jpg 0.28082782893200825\n",
      "p08/face/1706.jpg 0.2616561521214867\n",
      "p01/face/2499.jpg 0.188201085963494\n",
      "p09/face/571.jpg 0.17787971454010898\n",
      "p05/face/1497.jpg 0.15635358751336093\n",
      "p09/face/1623.jpg 0.15570588264591437\n",
      "p03/face/1843.jpg 0.11845313584146638\n",
      "p02/face/178.jpg 0.08071584178115902\n",
      "p13/face/1291.jpg 0.0750567220269789\n",
      "p04/face/945.jpg 0.03199657174891934\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "for k, v in images_errors.items():\n",
    "    ix += 1\n",
    "    if ix <44980:\n",
    "        continue\n",
    "    print(k, v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb9e6165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p07/face/2403.jpg 14.295408161720603\n",
      "p11/face/2393.jpg 14.295255458495816\n",
      "p14/face/764.jpg 14.29499370438443\n",
      "p00/face/2486.jpg 14.29449243952885\n",
      "p12/face/2086.jpg 14.29437624097635\n",
      "p06/face/740.jpg 14.294375611948508\n",
      "p11/face/1567.jpg 14.29436846295525\n",
      "p06/face/992.jpg 14.293851485315091\n",
      "p05/face/2216.jpg 14.293712925089634\n",
      "p12/face/1558.jpg 14.29367103857881\n",
      "p03/face/973.jpg 14.293452126192403\n",
      "p07/face/881.jpg 14.293191301415717\n",
      "p06/face/2872.jpg 14.292567528827089\n",
      "p02/face/1865.jpg 14.292237452102388\n",
      "p06/face/82.jpg 14.291974075448627\n",
      "p01/face/1512.jpg 14.291141476785437\n",
      "p13/face/1731.jpg 14.291125422025544\n",
      "p13/face/2773.jpg 14.291034174930333\n",
      "p05/face/1240.jpg 14.29011159076981\n",
      "p01/face/2039.jpg 14.289443660533104\n",
      "p12/face/28.jpg 14.289237261181162\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "for k, v in images_errors.items():\n",
    "    ix += 1\n",
    "    if ix <22480 or ix >22500:\n",
    "        continue\n",
    "    print(k, v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
