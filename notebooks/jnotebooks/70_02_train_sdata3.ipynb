{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005def19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training script for training sdata3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c268e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import numpy as np\n",
    "\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import wandb\n",
    "\n",
    "import datasets\n",
    "from model import L2CS\n",
    "from utils import select_device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/project/modules/jmodules')\n",
    "from jutils import SynJSON as SJ, get_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b78d2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 27 16:04:59 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   39C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963cb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"Parse input arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Gaze estimation using L2CSNet')\n",
    "#     # Gaze360\n",
    "#     parser.add_argument(\n",
    "#         '--gaze360image_dir', dest='gaze360image_dir', help='Directory path for gaze images.',\n",
    "#         default='datasets/Gaze360/Image', type=str)\n",
    "#     parser.add_argument(\n",
    "#         '--gaze360label_dir', dest='gaze360label_dir', help='Directory path for gaze labels.',\n",
    "#         default='datasets/Gaze360/Label/train.label', type=str)\n",
    "#     # mpiigaze\n",
    "    parser.add_argument(\n",
    "        '--gazeMpiimage_dir', dest='gazeMpiimage_dir', help='Directory path for gaze images.',\n",
    "        default='/project/data/sdata3/Image', type=str)\n",
    "    parser.add_argument(\n",
    "        '--gazeMpiilabel_dir', dest='gazeMpiilabel_dir', help='Directory path for gaze labels.',\n",
    "        default='/project/data/sdata3/Label', type=str)\n",
    "\n",
    "    # Important args -------------------------------------------------------------------------------------------------------\n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "    parser.add_argument(\n",
    "        '--dataset', dest='dataset', help='mpiigaze, rtgene, gaze360, ethgaze',\n",
    "        default= \"mpiigaze\", type=str)\n",
    "    parser.add_argument(\n",
    "        '--output', dest='output', help='Path of output models.',\n",
    "        default='/project/results/soutput3/snapshots/', type=str)\n",
    "    parser.add_argument(\n",
    "        '--snapshot', dest='snapshot', help='Path of model snapshot.',\n",
    "        default='/project/results/soutput3/snapshots/', type=str)\n",
    "    parser.add_argument(\n",
    "        '--gpu', dest='gpu_id', help='GPU device id to use [0] or multiple 0,1,2,3',\n",
    "        default='0,1,2,3', type=str)\n",
    "    parser.add_argument(\n",
    "        '--evalpath', dest='evalpath', help='path to save the evaluation results',\n",
    "        default='/project/results/soutput3/evaluation/', type=str)\n",
    "    parser.add_argument(\n",
    "        '--num_epochs', dest='num_epochs', help='Maximum number of training epochs.',\n",
    "        default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        '--batch_size', dest='batch_size', help='Batch size.',\n",
    "        default=100, type=int)\n",
    "    parser.add_argument(\n",
    "        '--arch', dest='arch', help='Network architecture, can be: ResNet18, ResNet34, [ResNet50], ''ResNet101, ResNet152, Squeezenet_1_0, Squeezenet_1_1, MobileNetV2',\n",
    "        default='ResNet50', type=str)\n",
    "    parser.add_argument(\n",
    "        '--alpha', dest='alpha', help='Regression loss coefficient.',\n",
    "        default=1, type=float)\n",
    "    parser.add_argument(\n",
    "        '--lr', dest='lr', help='Base learning rate.',\n",
    "        default=0.00001, type=float)\n",
    "    parser.add_argument(\n",
    "        '--bins', dest='bins', help='number of angle bins',\n",
    "        default=28, type=int)\n",
    "    parser.add_argument(\n",
    "        '--angle', dest='angle', help='angle limit',\n",
    "        default=180, type=int)\n",
    "    parser.add_argument(\n",
    "        '--bin_width', dest='bin_width', help='width of anlge bins',\n",
    "        default=4, type=int)\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------------------------\n",
    "    # Important args ------------------------------------------------------------------------------------------------------\n",
    "    args = parser.parse_args(['--angle', '180'])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc056dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2658665",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandbproject = 'sdata3_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ignored_params(model):\n",
    "    # Generator function that yields ignored params.\n",
    "    b = [model.conv1, model.bn1, model.fc_finetune]\n",
    "    for i in range(len(b)):\n",
    "        for module_name, module in b[i].named_modules():\n",
    "            if 'bn' in module_name:\n",
    "                module.eval()\n",
    "            for name, param in module.named_parameters():\n",
    "                yield param\n",
    "\n",
    "def get_non_ignored_params(model):\n",
    "    # Generator function that yields params that will be optimized.\n",
    "    b = [model.layer1, model.layer2, model.layer3, model.layer4]\n",
    "    for i in range(len(b)):\n",
    "        for module_name, module in b[i].named_modules():\n",
    "            if 'bn' in module_name:\n",
    "                module.eval()\n",
    "            for name, param in module.named_parameters():\n",
    "                yield param\n",
    "\n",
    "def get_fc_params(model):\n",
    "    # Generator function that yields fc layer params.\n",
    "    b = [model.fc_yaw_gaze, model.fc_pitch_gaze]\n",
    "    for i in range(len(b)):\n",
    "        for module_name, module in b[i].named_modules():\n",
    "            for name, param in module.named_parameters():\n",
    "                yield param\n",
    "                \n",
    "def load_filtered_state_dict(model, snapshot):\n",
    "    # By user apaszke from discuss.pytorch.org\n",
    "    model_dict = model.state_dict()\n",
    "    snapshot = {k: v for k, v in snapshot.items() if k in model_dict}\n",
    "    model_dict.update(snapshot)\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "\n",
    "def getArch_weights(arch, bins):\n",
    "    if arch == 'ResNet18':\n",
    "        model = L2CS(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2], bins)\n",
    "        pre_url = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'\n",
    "    elif arch == 'ResNet34':\n",
    "        model = L2CS(torchvision.models.resnet.BasicBlock, [3, 4, 6, 3], bins)\n",
    "        pre_url = 'https://download.pytorch.org/models/resnet34-333f7ec4.pth'\n",
    "    elif arch == 'ResNet101':\n",
    "        model = L2CS(torchvision.models.resnet.Bottleneck, [3, 4, 23, 3], bins)\n",
    "        pre_url = 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'\n",
    "    elif arch == 'ResNet152':\n",
    "        model = L2CS(torchvision.models.resnet.Bottleneck,[3, 8, 36, 3], bins)\n",
    "        pre_url = 'https://download.pytorch.org/models/resnet152-b121ed2d.pth'\n",
    "    else:\n",
    "        if arch != 'ResNet50':\n",
    "            print('Invalid value for architecture is passed! '\n",
    "                  'The default value of ResNet50 will be used instead!')\n",
    "        model = L2CS(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3], bins)\n",
    "        pre_url = 'https://download.pytorch.org/models/resnet50-19c8e357.pth'\n",
    "\n",
    "    return model, pre_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parse_args()\n",
    "cudnn.enabled = True\n",
    "num_epochs = args.num_epochs\n",
    "batch_size = args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = select_device(args.gpu_id, batch_size=args.batch_size)\n",
    "# print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3beb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=args.dataset\n",
    "alpha = args.alpha\n",
    "output=args.output\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "folder = os.listdir(args.gazeMpiilabel_dir)\n",
    "folder.sort()\n",
    "testlabelpathcombined = [os.path.join(args.gazeMpiilabel_dir, j) for j in folder]\n",
    "dataset = datasets.Mpiigaze(testlabelpathcombined,args.gazeMpiimage_dir, transformations, True, 180, fold=-1)\n",
    "num_bins = dataset.n_angle_bins\n",
    "\n",
    "wandb.init(project=wandbproject, name='sdata3_train_errors')\n",
    "print(f'num_bins={num_bins}')\n",
    "print(f'total lines = {len(dataset.lines)}')\n",
    "model, pre_url = getArch_weights(args.arch, num_bins)\n",
    "print(model.conv1)\n",
    "load_filtered_state_dict(model, model_zoo.load_url(pre_url))\n",
    "print('Loading data.')\n",
    "# dataset=datasets.Mpiigaze(testlabelpathcombined,args.gazeMpiimage_dir, transformations, True, 180, fold)\n",
    "\n",
    "train_loader_gaze = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=int(batch_size),\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# fold_path = os.path.join(output, 'fold' + f'{fold:0>2}'+'/')\n",
    "now=get_now()\n",
    "print(f\"output is {output} {now}\")\n",
    "if not os.path.exists(output):\n",
    "     os.makedirs(output)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "reg_criterion = nn.MSELoss().cuda(gpu)\n",
    "softmax = nn.Softmax(dim=1).cuda(gpu)\n",
    "idx_tensor = [idx for idx in range(num_bins)]\n",
    "idx_tensor = Variable(torch.FloatTensor(idx_tensor)).cuda(gpu)\n",
    "\n",
    "#### origianally wrong number of arguments\n",
    "optimizer_gaze = torch.optim.Adam([\n",
    "    {'params': get_ignored_params(model), 'lr': 0}, \n",
    "    {'params': get_non_ignored_params(model), 'lr': args.lr},\n",
    "    {'params': get_fc_params(model), 'lr': args.lr}\n",
    "], args.lr)\n",
    "\n",
    "\n",
    "\n",
    "configuration = f\"\\ntrain configuration, gpu_id={args.gpu_id}, batch_size={batch_size}, model_arch={args.arch}\\n Start training dataset={data_set}, loader={len(train_loader_gaze)}--------------\\n\"\n",
    "print(configuration)\n",
    "model.to(gpu)\n",
    "model = nn.DataParallel(model, device_ids=[0,1,2,3])\n",
    "now = get_now()\n",
    "print(f'start training at {now}')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    sum_loss_pitch_gaze = sum_loss_yaw_gaze = iter_gaze = 0\n",
    "\n",
    "    for i, (images_gaze, labels_gaze, cont_labels_gaze,name) in enumerate(train_loader_gaze):\n",
    "        images_gaze = Variable(images_gaze).cuda(gpu)\n",
    "#         print(f'epoch : {epoch}, batch: {i}', end= ' ')\n",
    "        # Binned labels\n",
    "        label_pitch_gaze = Variable(labels_gaze[:, 0]).cuda(gpu)\n",
    "        label_yaw_gaze = Variable(labels_gaze[:, 1]).cuda(gpu)\n",
    "\n",
    "        # Continuous labels\n",
    "        label_pitch_cont_gaze = Variable(cont_labels_gaze[:, 0]).cuda(gpu)\n",
    "        label_yaw_cont_gaze = Variable(cont_labels_gaze[:, 1]).cuda(gpu)\n",
    "\n",
    "        pitch, yaw = model(images_gaze)\n",
    "\n",
    "        # Cross entropy loss\n",
    "        loss_pitch_gaze = criterion(pitch, label_pitch_gaze)\n",
    "        loss_yaw_gaze = criterion(yaw, label_yaw_gaze)\n",
    "\n",
    "        # MSE loss\n",
    "        pitch_predicted = softmax(pitch)\n",
    "        yaw_predicted = softmax(yaw)\n",
    "\n",
    "        # mapping from binned (0 to 28) to angels (-52 to 52) \n",
    "        pitch_predicted = \\\n",
    "            torch.sum(pitch_predicted * idx_tensor, 1) * 3 - 42\n",
    "        yaw_predicted = \\\n",
    "            torch.sum(yaw_predicted * idx_tensor, 1) * 3 - 42\n",
    "\n",
    "        loss_reg_pitch = reg_criterion(\n",
    "            pitch_predicted, label_pitch_cont_gaze)\n",
    "        loss_reg_yaw = reg_criterion(\n",
    "            yaw_predicted, label_yaw_cont_gaze)\n",
    "\n",
    "        # Total loss\n",
    "        loss_pitch_gaze += alpha * loss_reg_pitch\n",
    "        loss_yaw_gaze += alpha * loss_reg_yaw\n",
    "\n",
    "        sum_loss_pitch_gaze += loss_pitch_gaze\n",
    "        sum_loss_yaw_gaze += loss_yaw_gaze\n",
    "\n",
    "\n",
    "        loss_seq = [loss_pitch_gaze, loss_yaw_gaze]\n",
    "        grad_seq = \\\n",
    "            [torch.tensor(1.0).cuda(gpu) for _ in range(len(loss_seq))]\n",
    "\n",
    "        optimizer_gaze.zero_grad(set_to_none=True)\n",
    "        torch.autograd.backward(loss_seq, grad_seq)\n",
    "        optimizer_gaze.step()\n",
    "\n",
    "        iter_gaze += 1\n",
    "        yaw_loss = sum_loss_pitch_gaze/iter_gaze\n",
    "        pitch_loss = sum_loss_yaw_gaze/iter_gaze\n",
    "\n",
    "        iterations = len(dataset)//batch_size\n",
    "        div10 = iterations/10\n",
    "        if (i) % div10 == 0:  #for every div10 batches\n",
    "            now=time.time()\n",
    "            elapsed = now-start\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Iter [{i+1}/{len(dataset)//batch_size}] Losses: '\n",
    "                    f'Gaze Yaw {yaw_loss:.4f},Gaze Pitch {pitch_loss:.3f}'\n",
    "                     f' elapsed:{elapsed:.1f}s')\n",
    "\n",
    "    wandb.log({f'pitch_loss':pitch_loss, f'yaw_loss':yaw_loss }, step=epoch+1)\n",
    "    \n",
    "    if epoch % 1 == 0 and epoch < num_epochs:\n",
    "        now=get_now()\n",
    "        print(f\"epoch = {epoch+1}, {now}\")\n",
    "        checkf = 'epoch_' + str(epoch+1) + '.pkl'\n",
    "        pathf = os.path.join(output,checkf)\n",
    "        print(pathf)\n",
    "        print('Taking snapshot...')\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_gaze\n",
    "                .state_dict(),\n",
    "            'pitch_loss': pitch_loss,\n",
    "            'yaw_loss': yaw_loss\n",
    "            }, pathf)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1594c041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfb53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3703a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9969d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac279c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
