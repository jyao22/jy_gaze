{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9132df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model for each checkpoint folder to test maes for all data folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662efc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os, argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import wandb\n",
    "\n",
    "import datasets\n",
    "# from utils import select_device, natural_keys, gazeto3d, angular, getArch\n",
    "from utils import select_device, natural_keys, gazeto3d, angular, getArch\n",
    "from model import L2CS\n",
    "sys.path.append('/project/modules/jmodules')\n",
    "from jutils import get_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f3b0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/notebooks/jnotebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52aedb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 28 06:05:42 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   42C    P0    48W / 300W |   2074MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ee6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"Parse input arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Gaze estimation using L2CSNet')\n",
    "#     # Gaze360\n",
    "#     parser.add_argument(\n",
    "#         '--gaze360image_dir', dest='gaze360image_dir', help='Directory path for gaze images.',\n",
    "#         default='datasets/Gaze360/Image', type=str)\n",
    "#     parser.add_argument(\n",
    "#         '--gaze360label_dir', dest='gaze360label_dir', help='Directory path for gaze labels.',\n",
    "#         default='datasets/Gaze360/Label/train.label', type=str)\n",
    "#     # mpiigaze\n",
    "    parser.add_argument(\n",
    "        '--gazeMpiimage_dir', dest='gazeMpiimage_dir', help='Directory path for gaze images.',\n",
    "        default='/project/data/sdata3/Image', type=str)\n",
    "    parser.add_argument(\n",
    "        '--gazeMpiilabel_dir', dest='gazeMpiilabel_dir', help='Directory path for gaze labels.',\n",
    "        default='/project/data/sdata3/Label', type=str)\n",
    "\n",
    "    # Important args -------------------------------------------------------------------------------------------------------\n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "    parser.add_argument(\n",
    "        '--dataset', dest='dataset', help='mpiigaze, rtgene, gaze360, ethgaze',\n",
    "        default= \"mpiigaze\", type=str)\n",
    "    parser.add_argument(\n",
    "        '--output', dest='output', help='Path of output models.',\n",
    "        default='/project/results/soutput3/snapshots/', type=str)\n",
    "    parser.add_argument(\n",
    "        '--snapshot', dest='snapshot', help='Path of model snapshot.',\n",
    "        default='/project/results/soutput3/snapshots/', type=str)\n",
    "    parser.add_argument(\n",
    "        '--gpu', dest='gpu_id', help='GPU device id to use [0] or multiple 0,1,2,3',\n",
    "        default='0', type=str)\n",
    "    parser.add_argument(\n",
    "        '--evalpath', dest='evalpath', help='path to save the evaluation results',\n",
    "        default='/project/results/soutput3/evaluation/', type=str)\n",
    "    parser.add_argument(\n",
    "        '--num_epochs', dest='num_epochs', help='Maximum number of training epochs.',\n",
    "        default=60, type=int)\n",
    "    parser.add_argument(\n",
    "        '--batch_size', dest='batch_size', help='Batch size.',\n",
    "        default=100, type=int)\n",
    "    parser.add_argument(\n",
    "        '--arch', dest='arch', help='Network architecture, can be: ResNet18, ResNet34, [ResNet50], ''ResNet101, ResNet152, Squeezenet_1_0, Squeezenet_1_1, MobileNetV2',\n",
    "        default='ResNet50', type=str)\n",
    "    parser.add_argument(\n",
    "        '--alpha', dest='alpha', help='Regression loss coefficient.',\n",
    "        default=1, type=float)\n",
    "    parser.add_argument(\n",
    "        '--lr', dest='lr', help='Base learning rate.',\n",
    "        default=0.00001, type=float)\n",
    "    parser.add_argument(\n",
    "        '--bins', dest='bins', help='number of angle bins',\n",
    "        default=28, type=int)\n",
    "    parser.add_argument(\n",
    "        '--angle', dest='angle', help='angle limit',\n",
    "        default=180, type=int)\n",
    "    parser.add_argument(\n",
    "        '--bin_width', dest='bin_width', help='width of anlge bins',\n",
    "        default=4, type=int)\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------------------------\n",
    "    # Important args ------------------------------------------------------------------------------------------------------\n",
    "    args = parser.parse_args(['--angle', '180'])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c3086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e11321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually used\n",
    "batch_size=args.batch_size\n",
    "arch=args.arch\n",
    "data_set=args.dataset\n",
    "# evalpath =args.evalpath\n",
    "snapshot_path = args.snapshot\n",
    "bins=args.bins\n",
    "angle=args.angle\n",
    "bin_width=args.bin_width\n",
    "gazeMpiimage_dir = args.gazeMpiimage_dir\n",
    "gazeMpiilabel_dir=args.gazeMpiilabel_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0504fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parse_args()\n",
    "cudnn.enabled = True\n",
    "gpu = select_device(args.gpu_id, batch_size=args.batch_size)\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "model_used= getArch(arch, bins)  #resnet50 and 28 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaa49c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of checkpoint files: 60\n"
     ]
    }
   ],
   "source": [
    "spath = Path(snapshot_path)\n",
    "ckfiles =[]\n",
    "for filename in sorted(spath.glob('*.pkl'), \n",
    "        key=lambda path: int(path.stem.rsplit(\"_\", 1)[1])):\n",
    "    ckfiles.append(filename)\n",
    "print(f'number of checkpoint files: {len(ckfiles)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "215953c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path=/project/data/sdata3/Label/test.label\n",
      "0 items removed from dataset that have an angle > 180\n"
     ]
    }
   ],
   "source": [
    "#labels\n",
    "lfolder = os.listdir(gazeMpiilabel_dir)\n",
    "lfolder.sort()  #individual label files\n",
    "testlabelpathcombined = [os.path.join(gazeMpiilabel_dir, j) for j in lfolder]\n",
    "gaze_dataset=datasets.Mpiigaze(testlabelpathcombined, gazeMpiimage_dir, transformations, False, angle, fold=-1)\n",
    "# print(testlabelpathcombined)\n",
    "\n",
    "model = model_used\n",
    "model= nn.DataParallel(model,device_ids=[0])  #important to load state dict\n",
    "\n",
    "# wandb.init(project='smodel_40_sdata', name='model_errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7c8aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/results/soutput3/snapshots/epoch_41.pkl\n"
     ]
    }
   ],
   "source": [
    "ckfile = ckfiles[40]\n",
    "print(ckfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dcb7137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5351277e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test configuration: gpu_id=cuda:0, batch_size=100\n",
      "model_arch=ResNet50 Start testing dataset=mpiigaze--07/27/2022 23:05:46--\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(ckfile)\n",
    "saved_state_dict = checkpoint['model_state_dict']\n",
    "model.load_state_dict(saved_state_dict)\n",
    "model.cuda(gpu)\n",
    "model.eval()\n",
    "idx_tensor = [idx for idx in range(bins)]\n",
    "idx_tensor = torch.FloatTensor(idx_tensor).cuda(gpu)\n",
    "# print(idx_tensor)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "#     best_model_maes =[]  # error for each data fold\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=gaze_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True)\n",
    "now = get_now()\n",
    "configuration = f\"\\ntest configuration: gpu_id={gpu}, batch_size={batch_size}\\n\"\n",
    "configuration += f\"model_arch={arch} Start testing dataset={data_set}--{now}--\\n\"\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ba774ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42767 428\n"
     ]
    }
   ],
   "source": [
    "print(len(gaze_dataset), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d082630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed7a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 100\n",
      "1 100 200\n",
      "2 100 300\n",
      "3 100 400\n",
      "4 100 500\n"
     ]
    }
   ],
   "source": [
    "total = 0  \n",
    "avg_error = .0\n",
    "with torch.no_grad():\n",
    "    for j, (images, labels, cont_labels, name) in enumerate(test_loader):\n",
    "        if j > 100:\n",
    "            break\n",
    "        images = Variable(images).cuda(gpu)\n",
    "        total += cont_labels.size(0)  #number of labels/images in the batch = batch_size\n",
    "        print(j, cont_labels.size(0), total)\n",
    "\n",
    "        label_pitch = cont_labels[:,0].float()*np.pi/180\n",
    "        label_yaw = cont_labels[:,1].float()*np.pi/180\n",
    "\n",
    "        gaze_pitch, gaze_yaw = model(images)\n",
    "        #gaze_pitch is of (batch_szie, 28)\n",
    "\n",
    "        # Binned predictions\n",
    "        _, pitch_bpred = torch.max(gaze_pitch.data, 1)\n",
    "        _, yaw_bpred = torch.max(gaze_yaw.data, 1)\n",
    "\n",
    "        # Continuous predictions\n",
    "        pitch_predicted = softmax(gaze_pitch)\n",
    "        yaw_predicted = softmax(gaze_yaw)\n",
    "\n",
    "        # mapping from binned (0 to 28) to angels (-42 to 42)                \n",
    "        pitch_predicted = \\\n",
    "            torch.sum(pitch_predicted * idx_tensor, 1).cpu() * 3 - 42\n",
    "        yaw_predicted = \\\n",
    "            torch.sum(yaw_predicted * idx_tensor, 1).cpu() * 3 - 42\n",
    "\n",
    "        pitch_predicted = pitch_predicted*np.pi/180\n",
    "        yaw_predicted = yaw_predicted*np.pi/180\n",
    "\n",
    "        for p,y,pl,yl in zip(pitch_predicted, yaw_predicted, label_pitch, label_yaw):\n",
    "#                 pl, yl = yl, pl*(-1.0)\n",
    "#             print(type(p), p)\n",
    "#             print(p.size(), y.size(), pl.size(), yl.size())\n",
    "            avg_error += angular(gazeto3d([p,y]), gazeto3d([pl,yl])) #accumulate over all batches\n",
    "\n",
    "mean_mae = avg_error/total  \n",
    "now = get_now()\n",
    "msg = f\"Total Num images Checked:{total}, MAE:{mean_mae}  {now}\"\n",
    "#         outfile.write(loger)\n",
    "# wandb.log({'Mean_MAE':mean_mae}, step=ckn+1)\n",
    "print(msg)\n",
    "#     best_model_maes.append(mean_mae) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68e1bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20f04eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor([0.9900])\n"
     ]
    }
   ],
   "source": [
    "print(type(x), x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
