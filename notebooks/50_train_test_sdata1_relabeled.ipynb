{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c268e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import wandb\n",
    "\n",
    "import datasets\n",
    "from model import L2CS\n",
    "from utils import select_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bac42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data/sdata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d997c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /project/data/sdata1/Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /project/data/sdata1/Image/face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963cb35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=argparse.Namespace()\n",
    "args.gazeMpiimage_dir = '/project/data/sdata1/Image'\n",
    "args.gazeMpiilabel_dir = '/project/data/sdata1/Label'\n",
    "args.output = '/project/results/soutput1/snapshots/'\n",
    "args.dataset = 'mpiigaze'\n",
    "args.snapshot=''\n",
    "args.gpu_id = '0,1,2,3'\n",
    "args.num_epochs = 60\n",
    "args.batch_size = 60\n",
    "args.arch = 'ResNet50'\n",
    "args.alpha = 1.0\n",
    "args.lr = 0.00001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ignored_params(model):\n",
    "    # Generator function that yields ignored params.\n",
    "    b = [model.conv1, model.bn1, model.fc_finetune]\n",
    "    for i in range(len(b)):\n",
    "        for module_name, module in b[i].named_modules():\n",
    "            if 'bn' in module_name:\n",
    "                module.eval()\n",
    "            for name, param in module.named_parameters():\n",
    "                yield param\n",
    "\n",
    "def get_non_ignored_params(model):\n",
    "    # Generator function that yields params that will be optimized.\n",
    "    b = [model.layer1, model.layer2, model.layer3, model.layer4]\n",
    "    for i in range(len(b)):\n",
    "        for module_name, module in b[i].named_modules():\n",
    "            if 'bn' in module_name:\n",
    "                module.eval()\n",
    "            for name, param in module.named_parameters():\n",
    "                yield param\n",
    "\n",
    "def get_fc_params(model):\n",
    "    # Generator function that yields fc layer params.\n",
    "    b = [model.fc_yaw_gaze, model.fc_pitch_gaze]\n",
    "    for i in range(len(b)):\n",
    "        for module_name, module in b[i].named_modules():\n",
    "            for name, param in module.named_parameters():\n",
    "                yield param\n",
    "                \n",
    "def load_filtered_state_dict(model, snapshot):\n",
    "    # By user apaszke from discuss.pytorch.org\n",
    "    model_dict = model.state_dict()\n",
    "    snapshot = {k: v for k, v in snapshot.items() if k in model_dict}\n",
    "    model_dict.update(snapshot)\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "\n",
    "def getArch_weights(arch, bins):\n",
    "    if arch == 'ResNet18':\n",
    "        model = L2CS(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2], bins)\n",
    "        pre_url = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'\n",
    "    elif arch == 'ResNet34':\n",
    "        model = L2CS(torchvision.models.resnet.BasicBlock, [3, 4, 6, 3], bins)\n",
    "        pre_url = 'https://download.pytorch.org/models/resnet34-333f7ec4.pth'\n",
    "    elif arch == 'ResNet101':\n",
    "        model = L2CS(torchvision.models.resnet.Bottleneck, [3, 4, 23, 3], bins)\n",
    "        pre_url = 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'\n",
    "    elif arch == 'ResNet152':\n",
    "        model = L2CS(torchvision.models.resnet.Bottleneck,[3, 8, 36, 3], bins)\n",
    "        pre_url = 'https://download.pytorch.org/models/resnet152-b121ed2d.pth'\n",
    "    else:\n",
    "        if arch != 'ResNet50':\n",
    "            print('Invalid value for architecture is passed! '\n",
    "                  'The default value of ResNet50 will be used instead!')\n",
    "        model = L2CS(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3], bins)\n",
    "        pre_url = 'https://download.pytorch.org/models/resnet50-19c8e357.pth'\n",
    "\n",
    "    return model, pre_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parse_args()\n",
    "cudnn.enabled = True\n",
    "num_epochs = args.num_epochs\n",
    "batch_size = args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = select_device(args.gpu_id, batch_size=args.batch_size)\n",
    "print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3beb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=args.dataset\n",
    "alpha = args.alpha\n",
    "output=args.output\n",
    "\n",
    "#448 is new\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_now():\n",
    "    now = datetime.utcnow()\n",
    "    now = now.astimezone(timezone('US/Pacific'))\n",
    "    date_format='%m/%d/%Y %H:%M:%S'\n",
    "    now = now.strftime(date_format) \n",
    "    return now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d4999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "num_bins=35\n",
    "\n",
    "folder = os.listdir(args.gazeMpiilabel_dir)\n",
    "folder.sort()\n",
    "testlabelpathcombined = [os.path.join(args.gazeMpiilabel_dir, j) for j in folder]\n",
    "for fold in range(15):\n",
    "    \n",
    "    wandb.init(project='50_sdata1_training')\n",
    "    \n",
    "    model, pre_url = getArch_weights(args.arch, num_bins)\n",
    "    print(fold, model.conv1)\n",
    "    load_filtered_state_dict(model, model_zoo.load_url(pre_url))\n",
    "    print('Loading data.')\n",
    "    dataset=datasets.Mpiigaze(testlabelpathcombined,args.gazeMpiimage_dir, transformations, True, 180, fold)\n",
    "    \n",
    "    train_loader_gaze = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=int(batch_size),\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True)\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    fold_path = os.path.join(output, 'fold' + f'{fold:0>2}'+'/')\n",
    "    now=get_now()\n",
    "    print(f\"fold_path is {fold_path} {now}\")\n",
    "    if not os.path.exists(fold_path):\n",
    "        os.makedirs(fold_path)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "    reg_criterion = nn.MSELoss().cuda(gpu)\n",
    "    softmax = nn.Softmax(dim=1).cuda(gpu)\n",
    "    idx_tensor = [idx for idx in range(num_bins)]\n",
    "    idx_tensor = Variable(torch.FloatTensor(idx_tensor)).cuda(gpu)\n",
    "\n",
    "    #### origianally wrong number of arguments\n",
    "    optimizer_gaze = torch.optim.Adam([\n",
    "        {'params': get_ignored_params(model), 'lr': 0}, \n",
    "        {'params': get_non_ignored_params(model), 'lr': args.lr},\n",
    "        {'params': get_fc_params(model), 'lr': args.lr}\n",
    "    ], args.lr)\n",
    "\n",
    "    \n",
    "    \n",
    "    configuration = f\"\\ntrain configuration, gpu_id={args.gpu_id}, batch_size={batch_size}, model_arch={args.arch}\\n Start training dataset={data_set}, loader={len(train_loader_gaze)}, fold={fold}--------------\\n\"\n",
    "#     print(configuration)\n",
    "    model.to(gpu)\n",
    "    model = nn.DataParallel(model, device_ids=[0,1,2,3])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        sum_loss_pitch_gaze = sum_loss_yaw_gaze = iter_gaze = 0\n",
    "\n",
    "        for i, (images_gaze, labels_gaze, cont_labels_gaze,name) in enumerate(train_loader_gaze):\n",
    "            images_gaze = Variable(images_gaze).cuda(gpu)\n",
    "\n",
    "            # Binned labels\n",
    "            label_pitch_gaze = Variable(labels_gaze[:, 0]).cuda(gpu)\n",
    "            label_yaw_gaze = Variable(labels_gaze[:, 1]).cuda(gpu)\n",
    "\n",
    "            # Continuous labels\n",
    "            label_pitch_cont_gaze = Variable(cont_labels_gaze[:, 0]).cuda(gpu)\n",
    "            label_yaw_cont_gaze = Variable(cont_labels_gaze[:, 1]).cuda(gpu)\n",
    "\n",
    "            pitch, yaw = model(images_gaze)\n",
    "\n",
    "            # Cross entropy loss\n",
    "            loss_pitch_gaze = criterion(pitch, label_pitch_gaze)\n",
    "            loss_yaw_gaze = criterion(yaw, label_yaw_gaze)\n",
    "\n",
    "            # MSE loss\n",
    "            pitch_predicted = softmax(pitch)\n",
    "            yaw_predicted = softmax(yaw)\n",
    "\n",
    "            # mapping from binned (0 to 28) to angels (-52 to 52) \n",
    "            pitch_predicted = \\\n",
    "                torch.sum(pitch_predicted * idx_tensor, 1) * 3 - 52\n",
    "            yaw_predicted = \\\n",
    "                torch.sum(yaw_predicted * idx_tensor, 1) * 3 - 52\n",
    "\n",
    "            loss_reg_pitch = reg_criterion(\n",
    "                pitch_predicted, label_pitch_cont_gaze)\n",
    "            loss_reg_yaw = reg_criterion(\n",
    "                yaw_predicted, label_yaw_cont_gaze)\n",
    "\n",
    "            \n",
    "            # Total loss\n",
    "            loss_pitch_gaze += alpha * loss_reg_pitch\n",
    "            loss_yaw_gaze += alpha * loss_reg_yaw\n",
    "\n",
    "            sum_loss_pitch_gaze += loss_pitch_gaze\n",
    "            sum_loss_yaw_gaze += loss_yaw_gaze\n",
    "\n",
    "            \n",
    "            \n",
    "            loss_seq = [loss_pitch_gaze, loss_yaw_gaze]\n",
    "            grad_seq = \\\n",
    "                [torch.tensor(1.0).cuda(gpu) for _ in range(len(loss_seq))]\n",
    "\n",
    "            optimizer_gaze.zero_grad(set_to_none=True)\n",
    "            torch.autograd.backward(loss_seq, grad_seq)\n",
    "            optimizer_gaze.step()\n",
    "\n",
    "            iter_gaze += 1\n",
    "            yaw_loss = sum_loss_pitch_gaze/iter_gaze\n",
    "            pitch_loss = sum_loss_yaw_gaze/iter_gaze\n",
    "            \n",
    "            iterations = len(dataset)//batch_size\n",
    "            div10 = iterations/10\n",
    "            if (i+1) % div10 == 0:  #for every div10 batches\n",
    "                now=time.time()\n",
    "                elapsed = now-start\n",
    "                \n",
    "\n",
    "                print(f'Fold: {fold} Epoch [{epoch+1}/{num_epochs}], Iter [{i+1}/{len(dataset)//batch_size}] Losses: '\n",
    "                        f'Gaze Yaw {yaw_loss:.4f},Gaze Pitch {pitch_loss:.3f}'\n",
    "                         f' elapsed:{elapsed:.1f}s')\n",
    "                \n",
    "                wandb.log({f'fold_{fold}_pitch_loss':pitch_loss, f'fold_{fold}_yaw_loss':yaw_loss })\n",
    "    \n",
    "        if epoch % 1 == 0 and epoch < num_epochs:\n",
    "            now=get_now()\n",
    "            print(f\"fold_path is {fold_path}, epoch = {epoch+1}, {now}\")\n",
    "            pathf = fold_path + 'epoch_' + str(epoch+1) + '.pkl'\n",
    "            print(pathf)\n",
    "            print('Taking snapshot...')\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer_gaze\n",
    "                    .state_dict(),\n",
    "                'pitch_loss': pitch_loss,\n",
    "                'yaw_loss': yaw_loss\n",
    "                }, pathf)\n",
    "            \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1594c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l /project/results/soutput1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfb53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# started at 11:05pm 6/23/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3703a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9969d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac279c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
